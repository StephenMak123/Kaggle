{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "940e9018f48becd6498f48bf0d8a2201d8e83931"
   },
   "source": [
    "**Titanic: Machine Learning from Disaster**\n",
    "\n",
    "**By Stephen Mak**\n",
    "\n",
    "The Titanic's maiden voyage was on April 15th, 1912, which killed 1502 out of 2224 (67.5%) of the onboard passengers. The intent of this competition is to determine which passengers were likely to survive using various machine learning tools.\n",
    "\n",
    "The exam question is to **predict if a passenger survived the sinking of the Titanic or not**.\n",
    "\n",
    "The metric used to evaluate the model will simply be the Rand accuracy. This is simply defined as the sum of True Positives (TP) and True Negatives (TN) divided by the number of examples.\n",
    "\n",
    "The most crude model would predict everyone to have not survived, regardless of other features. This crude model would achieve an accuracy of 67.5%, and thus this will be the baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97ed78075ec8d36702d373e61e646c32354097b2"
   },
   "source": [
    "Features available\n",
    "The response variable will be \"Survival\" which is a binary yes/no (1 or 0).\n",
    "\n",
    "Various features are available including:\n",
    "\n",
    "*  **\"PassengerId\"** - Unique passenger ID - Categorical\n",
    "    * Ranges from 1 to XXXX\n",
    "\n",
    "* **\"pclass\"**, - Ticket Class - Categorical (1 = 1st Class, 2 = 2nd Class, 3 = 3rd Class)\n",
    "    * This could be an important feature as the number of lifeboats available to each ticket class may have varied.\n",
    "\n",
    "*  **\"Sex\"** - Gender - (Probably) Binary, Categorical variable containing 2 classes, male or female\n",
    "    * This could be an important feature as it is believed that females and children were advised to leave the boat first.\n",
    "\n",
    "* **\"Age\"** - Passenger's age in years - Categorical / Continuous (can decide later)\n",
    "    * Note that if the age has been estimated, it will finish in \"xx.5\". Therefore, there is potential for feature engineering to create an \"estimated age yes/no\" feature. Note also if the age is less than 1 it is fractional.\n",
    "\n",
    "*  **\"sibsp\"** - Number of siblings/spouses onboard - Categorical\n",
    "    * defined as brother/sister/stepbrother/stepsister/husband/wife.\n",
    "\n",
    "*  **\"parch\"** - Number of parents/children onboard -Categorical\n",
    "    * defined as mother/father/daughter/son/stepdaughter/stepson.\n",
    "\n",
    "*  **\"ticket\"** - Ticket Number - Categorical / Continuous (can decide later)\n",
    "    * Has a weird structure. Need to understand\n",
    "\n",
    "*  **\"fare\"** - Passenger Fare - Continuous\n",
    "    * Range from XXXX to XXXX\n",
    "\n",
    "*  **\"cabin\"** - Cabin Number - Categorical\n",
    "    * Need to understand structure\n",
    "\n",
    "*  **\"embarked\"** - Port of Embarkation - Categorical\n",
    "    * C = Cherbourg (France), Q = Queenstown (now Cobh, Ireland), S = Southampton (UK)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d5603196f7f211a4af00368136efe3fe7d4e9da"
   },
   "source": [
    "**Interesting sidenotes**\n",
    "\n",
    "* Titanic only had enough lifeboats for 1178 people due to outdated maritime safety regulations.\n",
    "\n",
    "* Women and children were evacuated first, therefore, it is suspected that this will be crucial for the model.\n",
    "\n",
    "* RMS Carpathia arrived 2 hours later to save approximately 705 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "82a5c939189825c7b3a68631fe6bbdf58bc388cb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path('C:/Users/Stephen/Desktop/Documents/A Learning Journey/Kaggle/Titanic/')\n",
    "TRAIN = PATH/'/train/train.csv'\n",
    "TEST = PATH/'/test/test.csv'\n",
    "\n",
    "pd.options.display.max_columns = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69407bfa57748b0863e3c45421fa447ce770f9b0"
   },
   "source": [
    "First, let's read in the data and explore the dataset to better understand the data and what features could be useful for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "69a7fcc16dfbdbc0f16315471a2aec827effc06e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\train\\\\train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a69377f12f76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcolumns_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SibSp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ParCh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TicketNo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Price'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CabinNo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EmbarkCity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\train\\\\train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "columns = ['ID', 'Survived', 'Class', 'Name', 'Sex', 'Age', 'SibSp', 'ParCh', 'TicketNo', 'Price', 'CabinNo', 'EmbarkCity']\n",
    "columns_test = ['ID', 'Class', 'Name', 'Sex', 'Age', 'SibSp', 'ParCh', 'TicketNo', 'Price', 'CabinNo', 'EmbarkCity']\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(TRAIN, names = columns, header=0)\n",
    "data_test = pd.read_csv(TEST, names = columns_test, header=0)\n",
    "\n",
    "print(data_test.head())\n",
    "# print(data.columns)\n",
    "# print(data.dtypes)\n",
    "# print(data.head(5))\n",
    "# print(data.describe(include='all'))\n",
    "# print(data.count())\n",
    "\n",
    "cat_features = ['ID', 'Survived', 'Class', 'Name', 'Sex', 'SibSp', 'ParCh', 'TicketNo', 'CabinNo', 'EmbarkCity']\n",
    "cont_features = ['Age', 'Price']\n",
    "\n",
    "for feature in cat_features:\n",
    "    data[feature] = data[feature].astype('category').cat.as_ordered()\n",
    "    if feature == 'Survived':\n",
    "        continue\n",
    "    data_test[feature] = data_test[feature].astype('category').cat.as_ordered()\n",
    "    \n",
    "for feature in cont_features:\n",
    "    data[feature] = data[feature].fillna(data['Age'].median()).astype('float32')\n",
    "    data_test[feature] = data_test[feature].fillna(data['Age'].median()).astype('float32')\n",
    "\n",
    "# plt.hist(data['Age'], bins=20)\n",
    "# plt.show()\n",
    "\n",
    "# print(data['Age'].describe())\n",
    "# print(data.dtypes)\n",
    "# print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "033a80623c5a3843711d0374dc6ea34b07fc61ac"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(data['Age'], data['Price'])\n",
    "plt.xlabel('Age (Years)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.title('Price paid per ticket vs. Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9aed59db0638fcfe0f8f8b64e6af21cfc4eb100"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.lmplot(x='Age', y='Price', data=data, hue='Sex', palette='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc9f02341512c3b5f9fdbe1cd885b5e05a994cd5"
   },
   "outputs": [],
   "source": [
    "print(cat_features)\n",
    "print(cont_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45bd7ccd0ed9978bce89079318a38f69fa8a4a4f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.swarmplot(x='Sex', y='Price', hue='Survived', data=data)\n",
    "plt.savefig('Price vs. Gender.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23892e97930b5e93bff0eac8eeb50e3dc26e2175"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.swarmplot(x='Sex', y='Age', hue='Survived', data=data)\n",
    "plt.savefig('Age vs. Gender.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2705a9bcd1bc89ac0a459b899379972c1c3a755c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.swarmplot(x='Class', y='Age', hue='Survived', data=data)\n",
    "# plt.savefig('Age vs. Class.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdb7871358faec10329b9a87d1b20e5b27ebdc30"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.swarmplot(x='EmbarkCity', y='Price', hue='Survived', data=data)\n",
    "# plt.savefig('Age vs. Class.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0d4d0fe28504af96ba5b863ac5f8e9c5b32aca0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.swarmplot(x='SibSp', y='Price', hue='Survived', data=data)\n",
    "# plt.savefig('Age vs. Class.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7783fd76d15816587d9bbcf9d04a82dd2a08c403"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.pairplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b14f319fa6bef14a7839f1cdf8349df9d825568",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cov_matrix = data.corr()\n",
    "\n",
    "# sns.heatmap(cov_matrix)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c7a171d7fb3e373debee4f34f84ba85bf69cbda"
   },
   "source": [
    "**Time to do some feature engineering**\n",
    "\n",
    "Some features that may be useful for training:\n",
    "1. Is the passenger a child? i.e. is their age < 18? doesn't have to be 18, this number could change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a9855bb5e1850740363e83129eec5d2f8e9289d"
   },
   "outputs": [],
   "source": [
    "data['Survived'] = data['Survived'].astype('float32')\n",
    "\n",
    "sns.lmplot(x='Age', y='Survived', data=data, logistic=True, palette='Set1', hue='Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31e3e5f5fed6b7551c6c453e970bf3db3653da03"
   },
   "source": [
    "The older females had a greater probablility of survival; however, the inverse is true for males???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd2fa2bf928e4a6335a1d096d4d7749f4e2dfd10"
   },
   "outputs": [],
   "source": [
    "age = 18\n",
    "\n",
    "data['IsChild'] = np.where(data['Age'] <= age, '1', '0')\n",
    "data_test['IsChild'] = np.where(data_test['Age'] <= age, '1', '0')\n",
    "\n",
    "\n",
    "data_dummies = pd.get_dummies(data, columns = ['EmbarkCity', 'Sex'])\n",
    "data_test_dummies = pd.get_dummies(data_test, columns = ['EmbarkCity', 'Sex'])\n",
    "\n",
    "print(data_dummies.columns)\n",
    "print(data_test_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e254c96cc1212845d5c7910b98a0a0f49626e7d"
   },
   "outputs": [],
   "source": [
    "y = data_dummies['Survived'].values\n",
    "X = data_dummies.drop(columns = ['Survived','Name', 'TicketNo', 'CabinNo', 'EmbarkCity_C', 'Sex_male'], axis=1).values\n",
    "\n",
    "log_regression = LogisticRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=88, stratify=y)\n",
    "\n",
    "cv_results = cross_val_score(log_regression, X_train, y_train, cv=5)\n",
    "\n",
    "print(cv_results)\n",
    "print(np.mean(cv_results))\n",
    "\n",
    "log_regression.fit(X_train, y_train)\n",
    "\n",
    "# print(data_dummies.drop(columns=['Survived','Name', 'TicketNo', 'CabinNo', 'EmbarkCity_C', 'Sex_male'], axis=1).columns)\n",
    "# print(log_regression.coef_)\n",
    "# plt.plot(log_regression.coef_)\n",
    "# plt.show()\n",
    "\n",
    "y_pred = log_regression.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "scores = classification_report(y_test, y_pred)\n",
    "print(scores)\n",
    "\n",
    "sns.heatmap(conf_matrix, cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "# print(f'Test set predictions:\\n {y_pred}')\n",
    "\n",
    "print(f'Training Accuracy \\t Validation Accuracy \\n {log_regression.score(X_train, y_train)}, {log_regression.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9a71cf9e59defc200f1a1db73d0ed9aba8c1428",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = log_regression.predict(data_test_dummies.drop(columns=['Name', 'TicketNo', 'CabinNo', 'EmbarkCity_C', 'Sex_male'], axis=1)).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': data_test['ID'], 'Survived':y_pred})\n",
    "submission.to_csv('titanic_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3bd5c056f2557e96946e22dc43d7f2b68ca9dc8"
   },
   "source": [
    "Why reshape data (-1,1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(data.columns)\n",
    "\n",
    "# plt.plot(x, y, color = 'blue')\n",
    "# plt.xlabel\n",
    "# plt.ylabel\n",
    "# plt.title\n",
    "# plt.show\n",
    "# plt.axes([x_lo, y_lo, width, height])\n",
    "# plt.axis([x_min, x_max, y_min, y_max])\n",
    "# #Units in figure units, between 0 and 1.\n",
    "# ​\n",
    "# plt.subplot(2,1,1)\n",
    "# #Number rows, number columns, which subplot to make active. Order goes from top to bottom, left to right, indexed from 1.\n",
    "# plt.tight_layout()\n",
    "# #Pads spaces between subplots so that there is no overlap\n",
    "# ​\n",
    "# plt.annotate()\n",
    "# plt.style.use()\n",
    "# plt.style.available()\n",
    "# ​\n",
    "# plt.legend()\n",
    "# ​\n",
    "# plt.savefig()\n",
    "# ​\n",
    "# plt.hist()\n",
    "# plt.hist2d()\n",
    "# ​\n",
    "# plt.hexbin()\n",
    "# ​\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5fc267d99e37e6ccc0a393c0215080132c012cd",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
